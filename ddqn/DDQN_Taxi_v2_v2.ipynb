{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDQN_Taxi-v2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoRif9QKm4Mq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ddb6ee7-92b8-44b5-ef31-c6e5ad9ebb01"
      },
      "source": [
        "## install\n",
        "\n",
        "!apt-get install xvfb\n",
        "!pip install 'gym==0.10.11'\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install PILLOW\n",
        "!pip install 'pyglet==1.3.2'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents-nightly\n",
        "try:\n",
        "  %%tensorflow_version 2.x\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.3 [783 kB]\n",
            "Fetched 783 kB in 1s (958 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 145605 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.3_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting gym==0.10.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/04/70d4901b7105082c9742acd64728342f6da7cd471572fd0660a73f9cfe27/gym-0.10.11.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.17.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.10.11) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.10.11-cp36-none-any.whl size=1588314 sha256=6bbd43c0c500f05cdc95254a8ba484f9447421fd73bae82a96da945564831bf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/eb/1f/22c4124f3c64943aa0646daf4612b1c1f00f27d89b81304ebd\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Found existing installation: gym 0.15.4\n",
            "    Uninstalling gym-0.15.4:\n",
            "      Successfully uninstalled gym-0.15.4\n",
            "Successfully installed gym-0.10.11\n",
            "Collecting imageio==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/64/8e2bb6aac43d6ed7c2d9514320b43d5e80c00f150ee2b9408aee24359e6d/imageio-2.4.0.tar.gz (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio==2.4.0) (1.17.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.4.0) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio==2.4.0) (0.46)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-cp36-none-any.whl size=3303880 sha256=f490e6b3df58b38339534ff6988ad55ddcf9481a0ca5b69d76124b59b5f9d483\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/83/88/a1cba54ac06395d9e4ddcd9cf06911cd0b26cd78af9a61071b\n",
            "Successfully built imageio\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imageio\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.4.0\n",
            "Requirement already satisfied: PILLOW in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from PILLOW) (0.46)\n",
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/ad/b15f252bfb0f1693ad3150b55a44a674f3cba711cacdbb9ae2f03f143d19/PyVirtualDisplay-0.2.4-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/29/40040d1d64a224a5e44df9572794a66494618ffe5c77199214aeceedb8a7/EasyProcess-0.2.7-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.7 pyvirtualdisplay-0.2.4\n",
            "Collecting tf-agents-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/d7/dc01ad7f9f1f9339bb3aa9dcebf94da062533448c56c05d475fb0969434c/tf_agents_nightly-0.2.0.dev20191202-py2.py3-none-any.whl (808kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents-nightly) (1.17.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents-nightly) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents-nightly) (0.8.1)\n",
            "Collecting gin-config==0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/be/c984b1c8a7ba1c385b32bf39c7a225cd9f713d49705898309d01b60fd0e7/gin_config-0.1.3-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hCollecting tfp-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/0b/90660af759cee097c65d5a9f33fabb0d18c9189d358d362929c6f0b4b097/tfp_nightly-0.9.0.dev20191202-py2.py3-none-any.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tfp-nightly->tf-agents-nightly) (4.4.1)\n",
            "Requirement already satisfied: gast>=0.2 in /usr/local/lib/python3.6/dist-packages (from tfp-nightly->tf-agents-nightly) (0.2.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tfp-nightly->tf-agents-nightly) (1.2.2)\n",
            "Installing collected packages: gin-config, tfp-nightly, tf-agents-nightly\n",
            "  Found existing installation: gin-config 0.2.1\n",
            "    Uninstalling gin-config-0.2.1:\n",
            "      Successfully uninstalled gin-config-0.2.1\n",
            "Successfully installed gin-config-0.1.3 tf-agents-nightly-0.2.0.dev20191202 tfp-nightly-0.9.0.dev20191202\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeX3-CYnIDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16bc32a0-b95b-4fa3-97a7-fc58da041416"
      },
      "source": [
        "## setup\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.utils import common\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKS9UYu4nMHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## hyperparameter\n",
        "# num_iterations = 20000 # @param {type:\"integer\"}\n",
        "num_iterations = 5000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
        "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-4  # @param {type:\"number\"}\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(\n",
        "    learning_rate=learning_rate\n",
        ")\n",
        "\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "\n",
        "fc_layer_params = (100,50)\n",
        "train_step_counter = tf.Variable(0)\n",
        "collect_data_steps = 100\n",
        "\n",
        "replay_buffer_dataset_num_steps = 2\n",
        "\n",
        "# discout factor\n",
        "# default value is set as 1.0\n",
        "GAMMA = 0.6\n",
        "EPSILON = 0.1\n",
        "\n",
        "# defualt loss function\n",
        "TD_ERRORS_LOSS_FN = common.element_wise_huber_loss\n",
        "# TD_ERRORS_LOSS_FN = common.element_wise_squared_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1vuT-hEnR7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1980869b-0f5b-4b37-b45f-61d6800dd11c"
      },
      "source": [
        "## environment\n",
        "\n",
        "env_name = 'Taxi-v2'\n",
        "env = suite_gym.load(env_name)\n",
        "env.reset()\n",
        "env.render()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | :\u001b[43m \u001b[0m|\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ipykernel.iostream.OutStream at 0x7feda4c04748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDsFsLiUnaRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Train test environment\n",
        "\n",
        "# This is python environment\n",
        "train_py_env = suite_gym.load(env_name)\n",
        "eval_py_env = suite_gym.load(env_name)\n",
        "\n",
        "# But to run tf-agents, we need to convert to tensorflow environment\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVN643lknktH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## network\n",
        "\n",
        "# The below only set 1 hidden layer, which is 100 nodes densely connected layer\n",
        "# adding other arguments to build neural network\n",
        "q_net = q_network.QNetwork(\n",
        "    # input_tensor_spec (DQN input is state)\n",
        "    train_env.observation_spec(),\n",
        "    # action_spec (DQN output is action)\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgauUmtDn7zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## agent\n",
        "\n",
        "agent = dqn_agent.DdqnAgent(\n",
        "    # time_step_spec (something containing state and reward)\n",
        "    train_env.time_step_spec(),\n",
        "    # action_spec\n",
        "    train_env.action_spec(),\n",
        "    # q_network should be developed in advance, No default value\n",
        "    q_network=q_net,\n",
        "    # optimizer does not have default value\n",
        "    optimizer=optimizer,\n",
        "    # td_errors_loss_fn, default is element_wise_huber_loss, this example plays around this loss function\n",
        "    td_errors_loss_fn=TD_ERRORS_LOSS_FN,\n",
        "    # epsilon greedy algorithm, default is 1.0\n",
        "    epsilon_greedy = EPSILON,\n",
        "    # discount factor gamma, defaul is 1.0\n",
        "    gamma = GAMMA,\n",
        "    # counter for training\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNDPsODZoGgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## policy\n",
        "\n",
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy\n",
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGR-ZB0roOys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## evaluation function\n",
        "\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      # Do not use the below. It use tensor objects which cause error\n",
        "      # time_step = environment.step(action_step.action)\n",
        "      # For step argument, we put numpy object as action integer like below\n",
        "      time_step = eval_env.step(action_step.action.numpy()[0])\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAwnpAj0osZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## replay buffer\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLqmc6p-o5OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## function to collect data\n",
        "\n",
        "def collect_step(environment, policy, buffer):\n",
        "  time_step = environment.current_time_step()\n",
        "  action_step = policy.action(time_step)\n",
        "  # Do not use the below. It use tensor objects which cause error\n",
        "  # next_time_step = environment.step(action_step.action)\n",
        "  # For step argument, we put numpy object as action integer like below\n",
        "  next_time_step = environment.step(action_step.action.numpy()[0])\n",
        "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "  # Add trajectory to the replay buffer\n",
        "  buffer.add_batch(traj)\n",
        "\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "  for _ in range(steps):\n",
        "    collect_step(env, policy, buffer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80_Wm464o-Mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## data collection\n",
        "\n",
        "collect_data(train_env, random_policy, replay_buffer, steps=collect_data_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebl-CXNQprmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## training dataset\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3, \n",
        "    sample_batch_size=batch_size, \n",
        "    num_steps=replay_buffer_dataset_num_steps).prefetch(3)\n",
        "\n",
        "# by next(iterator), we can get batch training data for NN\n",
        "iterator = iter(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUG-NB8trKT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "229f5c42-e6a0-4287-b8be-0fec8b1724fe"
      },
      "source": [
        "## training\n",
        "\n",
        "#@test {\"skip\": true}\n",
        "#%%time\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "  for _ in range(collect_steps_per_iteration):\n",
        "    collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step = 200: loss = 0.6179594397544861\n",
            "step = 400: loss = 0.6405684947967529\n",
            "step = 600: loss = 0.41907572746276855\n",
            "step = 800: loss = 0.8326956033706665\n",
            "step = 1000: loss = 0.23735588788986206\n",
            "step = 1000: Average Return = -380.0\n",
            "step = 1200: loss = 0.5850425958633423\n",
            "step = 1400: loss = 0.5253002047538757\n",
            "step = 1600: loss = 0.7546030879020691\n",
            "step = 1800: loss = 0.6320357322692871\n",
            "step = 2000: loss = 0.368532657623291\n",
            "step = 2000: Average Return = -200.0\n",
            "step = 2200: loss = 0.4750916361808777\n",
            "step = 2400: loss = 0.6939660906791687\n",
            "step = 2600: loss = 0.28559252619743347\n",
            "step = 2800: loss = 0.4283487796783447\n",
            "step = 3000: loss = 0.6164989471435547\n",
            "step = 3000: Average Return = -200.0\n",
            "step = 3200: loss = 0.48323482275009155\n",
            "step = 3400: loss = 0.7699922323226929\n",
            "step = 3600: loss = 0.49397414922714233\n",
            "step = 3800: loss = 0.48620468378067017\n",
            "step = 4000: loss = 1.0366394519805908\n",
            "step = 4000: Average Return = -379.1000061035156\n",
            "step = 4200: loss = 0.8320658802986145\n",
            "step = 4400: loss = 0.8408799767494202\n",
            "step = 4600: loss = 0.6805537343025208\n",
            "step = 4800: loss = 0.8077001571655273\n",
            "step = 5000: loss = 1.0063079595565796\n",
            "step = 5000: Average Return = -200.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQyennNOrhkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e7b095fb-1c9e-48b7-d357-1f741a267891"
      },
      "source": [
        "## visualization\n",
        "\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "#plt.ylim(top=-100)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Iterations')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEGCAYAAACgt3iRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQkaUomIiKSNCUTERFJmpKJiIgk7f8DUvNnuYJOqaoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}