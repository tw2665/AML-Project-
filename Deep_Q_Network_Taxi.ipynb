{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Q_Network_Taxi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmVOuXTCt6CB",
        "colab_type": "text"
      },
      "source": [
        "# Deep Q Network for Taxi-v2 environment\n",
        "We use tf-agents to train Deep Q Network for Taxi-v2 environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puwH0-Z9uH2x",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_CD1cUXt41k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cd3f689-5f63-4005-f369-2580a703160c"
      },
      "source": [
        "!apt-get install xvfb\n",
        "!pip install 'gym==0.10.11'\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install PILLOW\n",
        "!pip install 'pyglet==1.3.2'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents-nightly\n",
        "try:\n",
        "  %%tensorflow_version 2.x\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.3 [783 kB]\n",
            "Fetched 783 kB in 0s (7,312 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 145605 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.3_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting gym==0.10.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/04/70d4901b7105082c9742acd64728342f6da7cd471572fd0660a73f9cfe27/gym-0.10.11.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.17.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.11) (2019.9.11)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.10.11) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.10.11-cp36-none-any.whl size=1588314 sha256=44aa0312420bdc0bfa18719e1aef4a3874e293648149e5c941c7581863a76025\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/eb/1f/22c4124f3c64943aa0646daf4612b1c1f00f27d89b81304ebd\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Found existing installation: gym 0.15.4\n",
            "    Uninstalling gym-0.15.4:\n",
            "      Successfully uninstalled gym-0.15.4\n",
            "Successfully installed gym-0.10.11\n",
            "Collecting imageio==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/64/8e2bb6aac43d6ed7c2d9514320b43d5e80c00f150ee2b9408aee24359e6d/imageio-2.4.0.tar.gz (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio==2.4.0) (1.17.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.4.0) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio==2.4.0) (0.46)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-cp36-none-any.whl size=3303880 sha256=ee0f5c4ce8e40c1176f392ef816934daa25263862661e5e1681e606980606dc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/83/88/a1cba54ac06395d9e4ddcd9cf06911cd0b26cd78af9a61071b\n",
            "Successfully built imageio\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imageio\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.4.0\n",
            "Requirement already satisfied: PILLOW in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from PILLOW) (0.46)\n",
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/ad/b15f252bfb0f1693ad3150b55a44a674f3cba711cacdbb9ae2f03f143d19/PyVirtualDisplay-0.2.4-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/29/40040d1d64a224a5e44df9572794a66494618ffe5c77199214aeceedb8a7/EasyProcess-0.2.7-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.7 pyvirtualdisplay-0.2.4\n",
            "Collecting tf-agents-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/b8/7681ae1ad77a6a27fdad6a37bdef02a2e40125a432d2ca1abe39c838c02d/tf_agents_nightly-0.2.0.dev20191125-py2.py3-none-any.whl (810kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents-nightly) (1.12.0)\n",
            "Collecting gin-config==0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/be/c984b1c8a7ba1c385b32bf39c7a225cd9f713d49705898309d01b60fd0e7/gin_config-0.1.3-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents-nightly) (1.17.4)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents-nightly) (0.8.1)\n",
            "Collecting tfp-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/f3/a668fb864979739acfe90f488c886176aa45e46528e13825850c4cb26cd1/tfp_nightly-0.9.0.dev20191125-py2.py3-none-any.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tfp-nightly->tf-agents-nightly) (4.4.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tfp-nightly->tf-agents-nightly) (1.2.2)\n",
            "Requirement already satisfied: gast>=0.2 in /usr/local/lib/python3.6/dist-packages (from tfp-nightly->tf-agents-nightly) (0.2.2)\n",
            "Installing collected packages: gin-config, tfp-nightly, tf-agents-nightly\n",
            "  Found existing installation: gin-config 0.2.1\n",
            "    Uninstalling gin-config-0.2.1:\n",
            "      Successfully uninstalled gin-config-0.2.1\n",
            "Successfully installed gin-config-0.1.3 tf-agents-nightly-0.2.0.dev20191125 tfp-nightly-0.9.0.dev20191125\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2LBeB7euQ-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d9298f44-d552-462e-cefa-e5aaaeecf510"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.utils import common\n",
        "\n",
        "# What's this?\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "# Set up a virtual display for rendering OpenAI gym environments.\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qm9cNpAuYpZ",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoMTrW9buX2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_iterations = 20000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
        "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5hlcckWugqV",
        "colab_type": "text"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0fqi7HGuiJa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "2dd54181-0c6d-4ebf-98e1-36eab153d535"
      },
      "source": [
        "env_name = 'Taxi-v2'\n",
        "env = suite_gym.load(env_name)\n",
        "env.reset()\n",
        "env.render()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "|\u001b[43m \u001b[0m| : | : |\n",
            "|\u001b[35mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ipykernel.iostream.OutStream at 0x7f765866aef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoD00vqjuyCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "d9c92f89-f185-4588-8970-f739fdc4b688"
      },
      "source": [
        "print('Observation Spec:', env.time_step_spec().observation)\n",
        "print('Reward Spec:', env.time_step_spec().reward)\n",
        "print('Action Spec:', env.action_spec())\n",
        "\n",
        "time_step = env.reset()\n",
        "print('Time step:', time_step)\n",
        "# When you input integers as action into step argument, you can get the next state\n",
        "action = 1\n",
        "next_time_step = env.step(action)\n",
        "print('Next time step:', next_time_step)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Spec: BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation', minimum=0, maximum=499)\n",
            "Reward Spec: ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
            "Action Spec: BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=5)\n",
            "Time step: TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(67))\n",
            "Next time step: TimeStep(step_type=array(1, dtype=int32), reward=array(-1., dtype=float32), discount=array(1., dtype=float32), observation=array(67))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMRGgCw2vWfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is python environment\n",
        "train_py_env = suite_gym.load(env_name)\n",
        "eval_py_env = suite_gym.load(env_name)\n",
        "\n",
        "# But to run tf-agents, we need to convert to tensorflow environment\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eooojMBmv2ea",
        "colab_type": "text"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLMf9p2Pv3s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc_layer_params = (100,)\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT1lZMRrv56C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2G4A-yQv8Wy",
        "colab_type": "text"
      },
      "source": [
        "## Policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzzKzHJMv9ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbUExZ6EwBht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN_bSShMwFsm",
        "colab_type": "text"
      },
      "source": [
        "## Metrics and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUjLSR9mwH9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      # Do not use the below. It use tensor objects which cause error\n",
        "      # time_step = environment.step(action_step.action)\n",
        "      # For step argument, we put numpy object as action integer like below\n",
        "      time_step = eval_env.step(action_step.action.numpy()[0])\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "258mg5O5wgV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b8608df7-7c50-46a4-b209-2a6678b3d7d5"
      },
      "source": [
        " compute_avg_return(eval_env, random_policy, num_eval_episodes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-727.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAgxUDeJwkUH",
        "colab_type": "text"
      },
      "source": [
        "## Replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m3_PzwKwmPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1PuS76Hwryw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9df02a15-9489-4425-9a3d-b3da56f32730"
      },
      "source": [
        "print(agent.collect_data_spec)\n",
        "print(agent.collect_data_spec._fields)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(499)), action=BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(5)), policy_info=(), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n",
            "('step_type', 'observation', 'action', 'policy_info', 'next_step_type', 'reward', 'discount')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6SxAxOYwweF",
        "colab_type": "text"
      },
      "source": [
        "## Data collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qdk_648wx_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_step(environment, policy, buffer):\n",
        "  time_step = environment.current_time_step()\n",
        "  action_step = policy.action(time_step)\n",
        "  # Do not use the below. It use tensor objects which cause error\n",
        "  # next_time_step = environment.step(action_step.action)\n",
        "  # For step argument, we put numpy object as action integer like below\n",
        "  next_time_step = environment.step(action_step.action.numpy()[0])\n",
        "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "  # Add trajectory to the replay buffer\n",
        "  buffer.add_batch(traj)\n",
        "\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "  for _ in range(steps):\n",
        "    collect_step(env, policy, buffer)\n",
        "\n",
        "collect_data(train_env, random_policy, replay_buffer, steps=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZeiE-xOxDKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "23baccf4-9ad5-493e-b4f0-a3431a26bcb6"
      },
      "source": [
        "# Dataset generates trajectories with shape [Bx2x...]\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3, \n",
        "    sample_batch_size=batch_size, \n",
        "    num_steps=2).prefetch(3)\n",
        "dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (Trajectory(step_type=(64, 2), observation=(64, 2), action=(64, 2), policy_info=(), next_step_type=(64, 2), reward=(64, 2), discount=(64, 2)), BufferInfo(ids=(64, 2), probabilities=(64,))), types: (Trajectory(step_type=tf.int32, observation=tf.int64, action=tf.int64, policy_info=(), next_step_type=tf.int32, reward=tf.float32, discount=tf.float32), BufferInfo(ids=tf.int64, probabilities=tf.float32))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdWdAoWDxHj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "126a653b-0c9c-4a3e-b6b1-cb702f03bf8b"
      },
      "source": [
        "iterator = iter(dataset)\n",
        "print(iterator)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.IteratorV2 object at 0x7f75fccc3240>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCAHPQDexO4Z",
        "colab_type": "text"
      },
      "source": [
        "## Training the agent\n",
        "The below program performs training with the number of num_iterations training, which is set in the Hyperparameter section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtLVok8RxQ3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b630be69-9eb4-47e1-8e4a-295ee5b343f9"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "%%time\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "  for _ in range(collect_steps_per_iteration):\n",
        "    collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step = 200: loss = 366524.5\n",
            "step = 400: loss = 1847954.75\n",
            "step = 600: loss = 3019845.25\n",
            "step = 800: loss = 11096424.0\n",
            "step = 1000: loss = 56869576.0\n",
            "step = 1000: Average Return = -200.0\n",
            "step = 1200: loss = 27826442.0\n",
            "step = 1400: loss = 32560820.0\n",
            "step = 1600: loss = 27534748.0\n",
            "step = 1800: loss = 299464960.0\n",
            "step = 2000: loss = 270226752.0\n",
            "step = 2000: Average Return = -200.0\n",
            "step = 2200: loss = 309522464.0\n",
            "step = 2400: loss = 524726784.0\n",
            "step = 2600: loss = 1121534336.0\n",
            "step = 2800: loss = 274359328.0\n",
            "step = 3000: loss = 1102817024.0\n",
            "step = 3000: Average Return = -200.0\n",
            "step = 3200: loss = 704739200.0\n",
            "step = 3400: loss = 2371959808.0\n",
            "step = 3600: loss = 1166410624.0\n",
            "step = 3800: loss = 946276992.0\n",
            "step = 4000: loss = 4520293376.0\n",
            "step = 4000: Average Return = -200.0\n",
            "step = 4200: loss = 2262018560.0\n",
            "step = 4400: loss = 4946981888.0\n",
            "step = 4600: loss = 5352407040.0\n",
            "step = 4800: loss = 5026588672.0\n",
            "step = 5000: loss = 3710523648.0\n",
            "step = 5000: Average Return = -200.0\n",
            "step = 5200: loss = 8709402624.0\n",
            "step = 5400: loss = 663262720.0\n",
            "step = 5600: loss = 153045440.0\n",
            "step = 5800: loss = 11426273280.0\n",
            "step = 6000: loss = 14017832960.0\n",
            "step = 6000: Average Return = -200.0\n",
            "step = 6200: loss = 2850757120.0\n",
            "step = 6400: loss = 1948278272.0\n",
            "step = 6600: loss = 6098464256.0\n",
            "step = 6800: loss = 12361682944.0\n",
            "step = 7000: loss = 3516331776.0\n",
            "step = 7000: Average Return = -200.0\n",
            "step = 7200: loss = 7631666688.0\n",
            "step = 7400: loss = 6542068736.0\n",
            "step = 7600: loss = 12929357824.0\n",
            "step = 7800: loss = 14385027072.0\n",
            "step = 8000: loss = 14466689024.0\n",
            "step = 8000: Average Return = -200.0\n",
            "step = 8200: loss = 25458487296.0\n",
            "step = 8400: loss = 19033954304.0\n",
            "step = 8600: loss = 21161660416.0\n",
            "step = 8800: loss = 40507617280.0\n",
            "step = 9000: loss = 42441424896.0\n",
            "step = 9000: Average Return = -200.0\n",
            "step = 9200: loss = 26406279168.0\n",
            "step = 9400: loss = 58039476224.0\n",
            "step = 9600: loss = 42117881856.0\n",
            "step = 9800: loss = 15780164608.0\n",
            "step = 10000: loss = 42156666880.0\n",
            "step = 10000: Average Return = -200.0\n",
            "step = 10200: loss = 44549373952.0\n",
            "step = 10400: loss = 51222249472.0\n",
            "step = 10600: loss = 47858302976.0\n",
            "step = 10800: loss = 48297041920.0\n",
            "step = 11000: loss = 64876306432.0\n",
            "step = 11000: Average Return = -200.0\n",
            "step = 11200: loss = 74905878528.0\n",
            "step = 11400: loss = 83010289664.0\n",
            "step = 11600: loss = 30351964160.0\n",
            "step = 11800: loss = 12966787072.0\n",
            "step = 12000: loss = 20870496256.0\n",
            "step = 12000: Average Return = -200.0\n",
            "step = 12200: loss = 64792215552.0\n",
            "step = 12400: loss = 74452049920.0\n",
            "step = 12600: loss = 82182742016.0\n",
            "step = 12800: loss = 85821472768.0\n",
            "step = 13000: loss = 134383353856.0\n",
            "step = 13000: Average Return = -200.0\n",
            "step = 13200: loss = 43549761536.0\n",
            "step = 13400: loss = 124675096576.0\n",
            "step = 13600: loss = 104699707392.0\n",
            "step = 13800: loss = 56851623936.0\n",
            "step = 14000: loss = 123269611520.0\n",
            "step = 14000: Average Return = -200.0\n",
            "step = 14200: loss = 48561905664.0\n",
            "step = 14400: loss = 218280312832.0\n",
            "step = 14600: loss = 68428234752.0\n",
            "step = 14800: loss = 140462358528.0\n",
            "step = 15000: loss = 72051769344.0\n",
            "step = 15000: Average Return = -200.0\n",
            "step = 15200: loss = 199252443136.0\n",
            "step = 15400: loss = 121935142912.0\n",
            "step = 15600: loss = 148782383104.0\n",
            "step = 15800: loss = 213257322496.0\n",
            "step = 16000: loss = 273774641152.0\n",
            "step = 16000: Average Return = -200.0\n",
            "step = 16200: loss = 354211790848.0\n",
            "step = 16400: loss = 183888150528.0\n",
            "step = 16600: loss = 121580847104.0\n",
            "step = 16800: loss = 66786910208.0\n",
            "step = 17000: loss = 288416301056.0\n",
            "step = 17000: Average Return = -200.0\n",
            "step = 17200: loss = 240644030464.0\n",
            "step = 17400: loss = 94553440256.0\n",
            "step = 17600: loss = 352669302784.0\n",
            "step = 17800: loss = 160874201088.0\n",
            "step = 18000: loss = 152665194496.0\n",
            "step = 18000: Average Return = -200.0\n",
            "step = 18200: loss = 720709681152.0\n",
            "step = 18400: loss = 113502617600.0\n",
            "step = 18600: loss = 274011291648.0\n",
            "step = 18800: loss = 550394265600.0\n",
            "step = 19000: loss = 227968630784.0\n",
            "step = 19000: Average Return = -200.0\n",
            "step = 19200: loss = 54404669440.0\n",
            "step = 19400: loss = 195484712960.0\n",
            "step = 19600: loss = 278230073344.0\n",
            "step = 19800: loss = 355226746880.0\n",
            "step = 20000: loss = 80891789312.0\n",
            "step = 20000: Average Return = -200.0\n",
            "CPU times: user 4min 59s, sys: 4.24 s, total: 5min 3s\n",
            "Wall time: 4min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5njogkxkoO",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLelJwvkxl7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "25a5a9f2-ceb9-427e-bc9b-a9b2687ff66d"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=250)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-2089.0549743652346, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}